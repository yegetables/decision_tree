不同特征决定不同的决策树。特征选择就是选取对训练数据集具有分类能力的特征，也就是决定用哪一个特征来划分特征空间，这样可以提高决策树的学习效率。通常特征选择的准则有信息增益、信息增益比、基尼指数、平方误差等等。

criterion是 DecisionTreeClassifier 类中的一个参数，用于指定划分节点时使用的度量标准。具体来说，它有以下三个可选值：

gini：使用基尼不纯度来进行划分，这是默认值。基尼不纯度是指从数据集中随机选择两个样本，这两个样本被错误地分类的概率。

entropy：使用信息熵来进行划分。信息熵是指从数据集中随机选择两个样本，这两个样本被错误地分类的期望信息量。

log_loss：对数损失函数，也称为逻辑回归损失。它在分类问题中用于评估分类器的概率估计。


